{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e950d5-03c0-4618-9785-6a19ba9fb209",
   "metadata": {},
   "source": [
    "## Retrieval Augumented Generation (RAG)\n",
    "\n",
    "Note: The two main challenges of Large Language Models are:\n",
    "    i) They only know the information they were tranined on \n",
    "    ii) They have limited context window - The length of the input that they can remember\n",
    "\n",
    "- To address both of these challenges, the technique call Retrieval Augumented Generation (RAG) can be employed. This technique allow us to intergrate \n",
    "external or domain specific knowledge to the LLM understanding.\n",
    "\n",
    "The typical RAG systm has three stages: \n",
    "    - Indexing - This happens ahead of time and allows you to quickly lookup relevant information at query-time. \n",
    "    - Retrieval - Given user's prompt, you Retrieve relevant documents from your external data source which will be later supplied to the LLM\n",
    "    - Generation - Use the LLM to generate a tailored answer in Natural Language using the supplied information\n",
    "\n",
    "This allows you to provide information that the model hasn't seen before, such as product-specific knowledge or live weather updates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31120e-e0e0-4984-813f-4586774474fa",
   "metadata": {},
   "source": [
    "### Install Chromadb - Open source vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac4ddb3-172d-4ff8-a36d-03854f04328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25165af5-54e4-42ef-9172-9cfcce8b02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai \n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fdfe259-91cc-429b-9893-87ad60276d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = 'AIzaSyD7Jojg3dYpSpUtOt7J6D89z5QZtpjEz8c'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa2cb4-c001-488a-9fac-c91dc3edf2eb",
   "metadata": {},
   "source": [
    "- We will use Gemini embedContent API method to calculate embeddings. Let's find a model that supports the embedContent functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac9fba2-df7a-4b1c-bf6e-6610a594315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if \"embedContent\" in model.supported_generation_methods:\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56bd8fd-8d3e-423b-a3f7-9a379ba9e09b",
   "metadata": {},
   "source": [
    "- We will use the models/text-embedding-004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb712c7c-e33e-4e49-8ea6-ba198fbfdfd2",
   "metadata": {},
   "source": [
    "### Data\n",
    "Below is a small set of documents to be used to create embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12848574-0240-4d21-b87a-573a2a7055a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8300306a-c255-449b-a0fb-475327d54bf1",
   "metadata": {},
   "source": [
    "### Creating the embedding database with ChromDB\n",
    "\n",
    "Create a custom function to generate embeddings with the Gemini API. In this task, you are implementing a retrieval system, so the task_type for generating the document embeddings is retrieval_document. Later, you will use retrieval_query for the query embeddings. Check out the API reference for the full list of supported tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de41f955-d1c0-4d5c-8b70-a2baf5a8858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    #specify wheather to generate embeddings for documents, or queries \n",
    "    document_mode = True\n",
    "\n",
    "    def __call__(self,input:Documents):\n",
    "        if self.document_mode: \n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        retry_policy = {\"retry\":retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "        response = genai.embed_content(\n",
    "            model = \"models/text-embedding-004\", \n",
    "            content = input, \n",
    "            task_type = embedding_task, \n",
    "            request_options=retry_policy\n",
    "        )\n",
    "        return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df821da-493b-453e-8789-a2fdd54eb8c2",
   "metadata": {},
   "source": [
    "Now we create a chroma database that uses the GeminiEmbedFunction and populate the database with the documents defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df3bde62-b77b-446d-95d0-08ebc5172a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the existing collection\n",
    "chroma_client.delete_collection(DB_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffab69-a9e2-4618-b124-6977aba31529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad517fc6-c431-4d59-8b9f-ec625a5d08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "DB_NAME = \"googlecardb\"\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "# from chromadb.utils import embedding_functions\n",
    "# embed_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "# embed_fn.document_mode = True\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54e648ef-bd60-4fab-a2fe-102a4c8a14a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70a230f5-66a0-47ad-aadb-6943d0da34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the collection\n",
    "# collection = chroma_client.get_collection(DB_NAME)\n",
    "# # Fetch all documents\n",
    "# xx = collection.get(include=[\"metadatas\", \"embeddings\", \"documents\"])\n",
    "# print(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab23a22-5da6-401e-a398-29fdf5b76758",
   "metadata": {},
   "source": [
    "### Retrieval: Find relevant documents \n",
    "Now to search the chroma database, call the query method. Note that you also switch to the retrieval_query mode of the embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "396515cb-f48d-48af-853b-57900cdd9c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to query mode when generating embeddings. \n",
    "embed_fn.document_mode = False\n",
    "\n",
    "#Search the Chroma DB using the specified query\n",
    "query = \"How do you use the touch screen to play music?\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[[passage]] = result['documents']\n",
    "Markdown(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7090af-2ff4-4e21-a55e-54c91a0c9c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91073eb3-902f-4d46-b0f1-179725fc0f16",
   "metadata": {},
   "source": [
    "### Augmented Generation: Answer the question\n",
    "\n",
    "Now that you have found a relevant passage from the set of documents (the retrieval step), you can now assemble a generation prompt to have the Gemini API generate a final answer. Note that in this example only a single passage was retrieved. In practice, especially when the size of your underlying data is large, you will want to retrieve more than one result and let the Gemini model determine what passages are relevant in answering the question. For this reason it's OK if some retrieved passages are not directly related to the question - this generation step should ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "137e8dbb-66f1-4fd1-ab73-f993b2a333af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: How do you use the touch screen to play music?\n",
      "PASSAGE: Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "PASSAGE: {passage_oneline}\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94b0d1-81f7-4587-a2ed-f27925b74502",
   "metadata": {},
   "source": [
    "- Now, we can use generate_content method to generate an answer to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362f9ca-545e-4d16-b319-94507e77e17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "892b50e4-d9ca-498f-b55c-b84ec6d3178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To play music on your Googlecar's touchscreen, simply touch the \"Music\" icon on the main display; it's that easy!  The touchscreen gives you access to lots of other things too, like navigation and climate control, all through simple taps on the screen.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6ce6e-6be6-4a28-9cdd-3f5cba690334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
